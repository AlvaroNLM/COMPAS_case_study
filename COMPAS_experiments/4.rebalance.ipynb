{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook **rebalanceamos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alvaronl/miniconda3/envs/jisbd/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "# import shap\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sesgos en COMPAS\n",
    "\n",
    "En esta sección, estudiaremos si el modelo COMPAS está sesgado comparando las puntuaciones obtenidas con la tasa real de reincidencia. En otras palabras, dadas dos personas con las mismas características excepto la raza, intentaremos analizar si el modelo sobreestima una puntuación más alta para una raza determinada. \n",
    "\n",
    "COMPAS funciona evaluando una serie de factores, entre los que se incluyen la edad, el sexo, los rasgos de personalidad, las medidas de aislamiento social, los antecedentes penales, la criminalidad familiar, la geografía y la situación laboral. Northpointe obtiene parte de esta información de los antecedentes penales y el resto de un cuestionario en el que se pide a los acusados que respondan a preguntas como «¿Cuántos de tus amigos/conocidos consumen drogas ilegales?» y que estén de acuerdo o en desacuerdo con afirmaciones como «Una persona hambrienta tiene derecho a robar».\n",
    "\n",
    "COMPAS devuelve una puntuación de 0 a 10 que indica el riesgo de reincidencia. Para facilitar la comparación, la puntuación decimal se transforma en una etiqueta binaria que indica riesgo alto (5-10) o riesgo bajo (1-4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv'\n",
    "df = pd.read_csv(url)\n",
    "df['high_risk'] = (df['decile_score'] >= 5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>compas_screening_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>c_jail_in</th>\n",
       "      <th>c_jail_out</th>\n",
       "      <th>c_case_number</th>\n",
       "      <th>c_offense_date</th>\n",
       "      <th>c_arrest_date</th>\n",
       "      <th>c_days_from_compas</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>c_charge_desc</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>r_case_number</th>\n",
       "      <th>r_charge_degree</th>\n",
       "      <th>r_days_from_arrest</th>\n",
       "      <th>r_offense_date</th>\n",
       "      <th>r_charge_desc</th>\n",
       "      <th>r_jail_in</th>\n",
       "      <th>r_jail_out</th>\n",
       "      <th>violent_recid</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>vr_case_number</th>\n",
       "      <th>vr_charge_degree</th>\n",
       "      <th>vr_offense_date</th>\n",
       "      <th>vr_charge_desc</th>\n",
       "      <th>type_of_assessment</th>\n",
       "      <th>decile_score.1</th>\n",
       "      <th>score_text</th>\n",
       "      <th>screening_date</th>\n",
       "      <th>v_type_of_assessment</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>v_screening_date</th>\n",
       "      <th>in_custody</th>\n",
       "      <th>out_custody</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "      <th>high_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>miguel hernandez</td>\n",
       "      <td>miguel</td>\n",
       "      <td>hernandez</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1947-04-18</td>\n",
       "      <td>69</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2013-08-13 06:03:42</td>\n",
       "      <td>2013-08-14 05:41:20</td>\n",
       "      <td>13011352CF10A</td>\n",
       "      <td>2013-08-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Aggravated Assault w/Firearm</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Risk of Recidivism</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>2014-07-07</td>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>kevon</td>\n",
       "      <td>dixon</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>Male</td>\n",
       "      <td>1982-01-22</td>\n",
       "      <td>34</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2013-01-26 03:45:27</td>\n",
       "      <td>2013-02-05 05:36:53</td>\n",
       "      <td>13001275CF10A</td>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Felony Battery w/Prior Convict</td>\n",
       "      <td>1</td>\n",
       "      <td>13009779CF10A</td>\n",
       "      <td>(F3)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-07-05</td>\n",
       "      <td>Felony Battery (Dom Strang)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>13009779CF10A</td>\n",
       "      <td>(F3)</td>\n",
       "      <td>2013-07-05</td>\n",
       "      <td>Felony Battery (Dom Strang)</td>\n",
       "      <td>Risk of Recidivism</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>2013-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>ed</td>\n",
       "      <td>philo</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1991-05-14</td>\n",
       "      <td>24</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2013-04-13 04:58:34</td>\n",
       "      <td>2013-04-14 07:02:04</td>\n",
       "      <td>13005330CF10A</td>\n",
       "      <td>2013-04-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Possession of Cocaine</td>\n",
       "      <td>1</td>\n",
       "      <td>13011511MM10A</td>\n",
       "      <td>(M1)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>Driving Under The Influence</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Risk of Recidivism</td>\n",
       "      <td>4</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>marcu brown</td>\n",
       "      <td>marcu</td>\n",
       "      <td>brown</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-01-21</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13000570CF10A</td>\n",
       "      <td>2013-01-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Possession of Cannabis</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Risk of Recidivism</td>\n",
       "      <td>8</td>\n",
       "      <td>High</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>bouthy pierrelouis</td>\n",
       "      <td>bouthy</td>\n",
       "      <td>pierrelouis</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>Male</td>\n",
       "      <td>1973-01-22</td>\n",
       "      <td>43</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12014130CF10A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-09</td>\n",
       "      <td>76.0</td>\n",
       "      <td>F</td>\n",
       "      <td>arrest case no charge</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Risk of Recidivism</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                name   first         last compas_screening_date   sex  \\\n",
       "0   1    miguel hernandez  miguel    hernandez            2013-08-14  Male   \n",
       "1   3         kevon dixon   kevon        dixon            2013-01-27  Male   \n",
       "2   4            ed philo      ed        philo            2013-04-14  Male   \n",
       "3   5         marcu brown   marcu        brown            2013-01-13  Male   \n",
       "4   6  bouthy pierrelouis  bouthy  pierrelouis            2013-03-26  Male   \n",
       "\n",
       "          dob  age          age_cat              race  juv_fel_count  \\\n",
       "0  1947-04-18   69  Greater than 45             Other              0   \n",
       "1  1982-01-22   34          25 - 45  African-American              0   \n",
       "2  1991-05-14   24     Less than 25  African-American              0   \n",
       "3  1993-01-21   23     Less than 25  African-American              0   \n",
       "4  1973-01-22   43          25 - 45             Other              0   \n",
       "\n",
       "   decile_score  juv_misd_count  juv_other_count  priors_count  \\\n",
       "0             1               0                0             0   \n",
       "1             3               0                0             0   \n",
       "2             4               0                1             4   \n",
       "3             8               1                0             1   \n",
       "4             1               0                0             2   \n",
       "\n",
       "   days_b_screening_arrest            c_jail_in           c_jail_out  \\\n",
       "0                     -1.0  2013-08-13 06:03:42  2013-08-14 05:41:20   \n",
       "1                     -1.0  2013-01-26 03:45:27  2013-02-05 05:36:53   \n",
       "2                     -1.0  2013-04-13 04:58:34  2013-04-14 07:02:04   \n",
       "3                      NaN                  NaN                  NaN   \n",
       "4                      NaN                  NaN                  NaN   \n",
       "\n",
       "   c_case_number c_offense_date c_arrest_date  c_days_from_compas  \\\n",
       "0  13011352CF10A     2013-08-13           NaN                 1.0   \n",
       "1  13001275CF10A     2013-01-26           NaN                 1.0   \n",
       "2  13005330CF10A     2013-04-13           NaN                 1.0   \n",
       "3  13000570CF10A     2013-01-12           NaN                 1.0   \n",
       "4  12014130CF10A            NaN    2013-01-09                76.0   \n",
       "\n",
       "  c_charge_degree                   c_charge_desc  is_recid  r_case_number  \\\n",
       "0               F    Aggravated Assault w/Firearm         0            NaN   \n",
       "1               F  Felony Battery w/Prior Convict         1  13009779CF10A   \n",
       "2               F           Possession of Cocaine         1  13011511MM10A   \n",
       "3               F          Possession of Cannabis         0            NaN   \n",
       "4               F           arrest case no charge         0            NaN   \n",
       "\n",
       "  r_charge_degree  r_days_from_arrest r_offense_date  \\\n",
       "0             NaN                 NaN            NaN   \n",
       "1            (F3)                 NaN     2013-07-05   \n",
       "2            (M1)                 0.0     2013-06-16   \n",
       "3             NaN                 NaN            NaN   \n",
       "4             NaN                 NaN            NaN   \n",
       "\n",
       "                 r_charge_desc   r_jail_in  r_jail_out  violent_recid  \\\n",
       "0                          NaN         NaN         NaN            NaN   \n",
       "1  Felony Battery (Dom Strang)         NaN         NaN            NaN   \n",
       "2  Driving Under The Influence  2013-06-16  2013-06-16            NaN   \n",
       "3                          NaN         NaN         NaN            NaN   \n",
       "4                          NaN         NaN         NaN            NaN   \n",
       "\n",
       "   is_violent_recid vr_case_number vr_charge_degree vr_offense_date  \\\n",
       "0                 0            NaN              NaN             NaN   \n",
       "1                 1  13009779CF10A             (F3)      2013-07-05   \n",
       "2                 0            NaN              NaN             NaN   \n",
       "3                 0            NaN              NaN             NaN   \n",
       "4                 0            NaN              NaN             NaN   \n",
       "\n",
       "                vr_charge_desc  type_of_assessment  decile_score.1 score_text  \\\n",
       "0                          NaN  Risk of Recidivism               1        Low   \n",
       "1  Felony Battery (Dom Strang)  Risk of Recidivism               3        Low   \n",
       "2                          NaN  Risk of Recidivism               4        Low   \n",
       "3                          NaN  Risk of Recidivism               8       High   \n",
       "4                          NaN  Risk of Recidivism               1        Low   \n",
       "\n",
       "  screening_date v_type_of_assessment  v_decile_score v_score_text  \\\n",
       "0     2013-08-14     Risk of Violence               1          Low   \n",
       "1     2013-01-27     Risk of Violence               1          Low   \n",
       "2     2013-04-14     Risk of Violence               3          Low   \n",
       "3     2013-01-13     Risk of Violence               6       Medium   \n",
       "4     2013-03-26     Risk of Violence               1          Low   \n",
       "\n",
       "  v_screening_date  in_custody out_custody  priors_count.1  start   end  \\\n",
       "0       2013-08-14  2014-07-07  2014-07-14               0      0   327   \n",
       "1       2013-01-27  2013-01-26  2013-02-05               0      9   159   \n",
       "2       2013-04-14  2013-06-16  2013-06-16               4      0    63   \n",
       "3       2013-01-13         NaN         NaN               1      0  1174   \n",
       "4       2013-03-26         NaN         NaN               2      0  1102   \n",
       "\n",
       "   event  two_year_recid  high_risk  \n",
       "0      0               0          0  \n",
       "1      1               1          0  \n",
       "2      0               1          0  \n",
       "3      0               0          1  \n",
       "4      0               0          0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentos\n",
    "\n",
    "Como no disponemos de las características de entrada necesarias para replicar el modelo COMPAS, entrenaremos un clasificador para predecir la puntuación COMPAS a partir del género, la raza, la edad, el número de antecedentes penales y el factor de delincuencia. Evaluaremos el modelo utilizando diferentes métricas de equidad y estudiaremos cómo los distintos métodos de reequilibrio de datos pueden afectar a estas métricas.\n",
    "\n",
    "\n",
    "SMOTE/Submuestreo/Sobremuestreo -> Entrenar -> Evaluar diferentes métricas.\n",
    "\n",
    "### Métricas a evaluar:\n",
    "\n",
    "Castelnovo, A., Crupi, R., Greco, G., & Regoli, D. (2021). The zoo of Fairness metrics in Machine Learning. arXiv preprint arXiv:2106.00467.\n",
    "\n",
    "\n",
    "INDEPENDENCIA (INDEPENDENCE)\n",
    "\n",
    "- **Paridad demográfica (Demographic parity)**: Ratio de predicción positiva entre dos razas.\n",
    "- **¿Paridad demográfica condicionada para principales? (Demographic parity conditioned on priors?)**\n",
    "\n",
    "SEPARACIÓN (SEPARATION)\n",
    "\n",
    "- **Igualdad predictiva (Predictive equality)** -> FPR\n",
    "- **Igualdad de oportunidades (Equality of opportunity)** -> FNR\n",
    "\n",
    "SUFICIENCIA (SUFFICIENCY)\n",
    "\n",
    "- **Paridad predictiva (Predictive parity)** -> Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fairness(y_pred, y_true, black_mask, white_mask):\n",
    "    y_pred_black = y_pred[black_mask]\n",
    "    y_true_black = y_true[black_mask]\n",
    "    y_pred_white = y_pred[white_mask]\n",
    "    y_true_white = y_true[white_mask]\n",
    "    # False Positive Rates FPR = FP / (FP + TN)\n",
    "    fpr_black = np.sum((y_pred_black == 1) * (y_true_black == 0)) / np.sum(y_true_black == 0)\n",
    "    fpr_white = np.sum((y_pred_white == 1) * (y_true_white == 0)) / np.sum(y_true_white == 0)\n",
    "    # True positive rates TPR = TP / (TP + FN)\n",
    "    tpr_black = np.sum((y_pred_black == 1)*(y_true_black == 1)) / np.sum(y_true_black == 1)\n",
    "    tpr_white = np.sum((y_pred_white == 1)*(y_true_white == 1)) / np.sum(y_true_white == 1)\n",
    "    # Precision\n",
    "    precision_black = precision_score(y_true_black, y_pred_black)\n",
    "    precision_white = precision_score(y_true_white, y_pred_white)\n",
    "\n",
    "    data = {}\n",
    "    data['TPR_w'] = tpr_white\n",
    "    data['TPR_b'] = tpr_black\n",
    "    data['FPR_w'] = fpr_white\n",
    "    data['FPR_b'] = fpr_black\n",
    "    data['Eq. Oportunity'] = abs(tpr_white-tpr_black)\n",
    "    data['Pred. Equality'] = abs(fpr_white-fpr_black)\n",
    "    data['Eq. odds'] = abs(tpr_white-tpr_black) + abs(fpr_white-fpr_black)\n",
    "    data['Accuracy'] = np.mean(y_pred == y_true)\n",
    "    # cm_tmp = confusion_matrix(y_true_black, y_pred_black)\n",
    "    # print(f\"cm black FPR: {cm_tmp[1,0]/(cm_tmp[1,0]+cm_tmp[0,0])}\")\n",
    "    # print(f\"FPR black: {fpr_black}\")\n",
    "    # print(f\"same?? {(cm_tmp[1,0]/(cm_tmp[1,0]+cm_tmp[0,0])) == fpr_black}\")\n",
    "\n",
    "    return data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE/Oversampling/Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_resampler(df, sampler=None, resample_test=False):\n",
    "\n",
    "#     # Prepare the data\n",
    "#     df_temp = df[(df['race'] == 'African-American') | (df['race'] == 'Caucasian')]\n",
    "#     cols = ['age', 'sex', 'race', 'priors_count', 'score_text']\n",
    "#     X, recid = df_temp[cols], df_temp['two_year_recid']\n",
    "#     X['score_text'] = [0 if y_i == 'Low' else 1 for y_i in X['score_text']]\n",
    "#     X = pd.get_dummies(X, drop_first=True)\n",
    "#     X_train, X_test, recid_train, recid_test = train_test_split(X, recid.values, test_size=0.2, random_state=42)\n",
    "\n",
    "#     ##############################\n",
    "#     # RESAMPLE THE TRAINING SET  #\n",
    "#     ##############################\n",
    "\n",
    "#     # Build target variable combining both the race and whether it has recivided or not\n",
    "#     #   - '00': Black, Non-recividist\n",
    "#     #   - '01': Black, Recividist\n",
    "#     #   - '10': White, Non-recividist\n",
    "#     #   - '11': White, Recividist\n",
    "#     if sampler:\n",
    "#         # get the race value\n",
    "#         y_race = X_train['race_Caucasian'].values\n",
    "#         # build the target variable\n",
    "#         y_sampler = np.array([str(a) + str(b) for a, b in zip(y_race, recid_train)])\n",
    "\n",
    "#         print(\"TRAINING SET:\")\n",
    "#         print(\"Before Sampling: \\n\\tBlack, Non-recidivist: {}\\n\\tBlack, Recidivist: {}\\\n",
    "#             \\n\\tWhite, Non-recidivist: {}\\n\\tWhite, Recidivist: {}\".format(np.sum(y_sampler == '00'), \\\n",
    "#             np.sum(y_sampler == '01'), np.sum(y_sampler == '10'), np.sum(y_sampler == '11')))\n",
    "\n",
    "#         # Sample the dataset according to the race and the recividism rates\n",
    "#         X_train, y_sampler = sampler.fit_resample(X_train, y_sampler)\n",
    "\n",
    "#         print(\"After Sampling: \\n\\tBlack, Non-recidivist: {}\\n\\tBlack, Recidivist: {}\\\n",
    "#             \\n\\tWhite, Non-recidivist: {}\\n\\tWhite, Recidivist: {}\".format(np.sum(y_sampler == '00'), \\\n",
    "#             np.sum(y_sampler == '01'), np.sum(y_sampler == '10'), np.sum(y_sampler == '11')))\n",
    "\n",
    "#         # Undo the label, i.e. get the race and the real recividism rate\n",
    "#         race, recid_train = np.array([int(y_i[0]) for y_i in y_sampler]), np.array([int(y_i[1]) for y_i in y_sampler])\n",
    "#         X_train['race_Caucasian'] = race \n",
    "        \n",
    "#     X_train, y_train = X_train.drop(columns='score_text'), X_train['score_text']\n",
    "\n",
    "#     ####################################\n",
    "#     # RESAMPLE THE TEST SET (OPTIONAL) #\n",
    "#     ####################################\n",
    "\n",
    "#     if resample_test and sampler:\n",
    "#     # get the race value\n",
    "#         y_race = X_test['race_Caucasian'].values\n",
    "#         # build the target variable\n",
    "#         y_sampler = np.array([str(a) + str(b) for a, b in zip(y_race, recid_test)])\n",
    "\n",
    "#         print(\"TEST SET:\")\n",
    "#         print(\"Before Sampling: \\n\\tBlack, Non-recidivist: {}\\n\\tBlack, Recidivist: {}\\\n",
    "#             \\n\\tWhite, Non-recidivist: {}\\n\\tWhite, Recidivist: {}\".format(np.sum(y_sampler == '00'), \\\n",
    "#             np.sum(y_sampler == '01'), np.sum(y_sampler == '10'), np.sum(y_sampler == '11')))\n",
    "\n",
    "#         # Sample the dataset according to the race and the recividism rates\n",
    "#         X_test, y_sampler = sampler.fit_resample(X_test, y_sampler)\n",
    "\n",
    "#         print(\"After Sampling: \\n\\tBlack, Non-recidivist: {}\\n\\tBlack, Recidivist: {}\\\n",
    "#             \\n\\tWhite, Non-recidivist: {}\\n\\tWhite, Recidivist: {}\".format(np.sum(y_sampler == '00'), \\\n",
    "#             np.sum(y_sampler == '01'), np.sum(y_sampler == '10'), np.sum(y_sampler == '11')))\n",
    "\n",
    "#         # Undo the label, i.e. get the race and the real recividism rate\n",
    "#         race, recid_test = np.array([int(y_i[0]) for y_i in y_sampler]), np.array([int(y_i[1]) for y_i in y_sampler])\n",
    "#         X_test['race_Caucasian'] = race \n",
    "\n",
    "#     X_test, y_test = X_test.drop(columns='score_text'), X_test['score_text']\n",
    "\n",
    "#     # Train the model\n",
    "\n",
    "#     clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "#     clf.fit(X_train, y_train)\n",
    "\n",
    "#     # Predict\n",
    "#     y_pred = clf.predict(X_test)\n",
    "\n",
    "#     black_mask = X_test['race_Caucasian'] == 0\n",
    "#     white_mask = X_test['race_Caucasian'] == 1\n",
    "\n",
    "#     # Evaluate fairness metrics\n",
    "#     data = eval_fairness(y_pred, recid_test, black_mask, white_mask)\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_resampler(df, sampler=None, resample_test=False):\n",
    "    \n",
    "    # --------------------------------------------------------\n",
    "    # 1. FILTRAR DATOS: Solo African-American y Caucasian\n",
    "    # --------------------------------------------------------\n",
    "    df_temp = df[(df[\"race\"] == \"African-American\") | (df[\"race\"] == \"Caucasian\")].copy()\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 2. PREPARACIÓN DE FEATURES\n",
    "    # --------------------------------------------------------\n",
    "    cols = [\"age\", \"sex\", \"priors_count\", \"score_text\"]\n",
    "    X = df_temp[cols].copy()\n",
    "\n",
    "    # score_text → 0 = Low, 1 = Medium/High\n",
    "    X[\"score_text\"] = (X[\"score_text\"] != \"Low\").astype(int)\n",
    "\n",
    "    # Codificar sex a 0/1\n",
    "    X[\"sex\"] = (X[\"sex\"] == \"Male\").astype(int)\n",
    "\n",
    "    # Codificar race a 0/1 para fairness\n",
    "    df_temp[\"race_bin\"] = (df_temp[\"race\"] == \"Caucasian\").astype(int)\n",
    "\n",
    "    # target recidivism (asegurar tipo entero)\n",
    "    recid = df_temp[\"two_year_recid\"].astype(int).values\n",
    "\n",
    "    # Añadimos la variable racial (0/1)\n",
    "    X[\"race_bin\"] = df_temp[\"race_bin\"].values\n",
    "\n",
    "    # One-hot encoding limpio\n",
    "    X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 3. SPLIT DATA\n",
    "    # --------------------------------------------------------\n",
    "    X_train, X_test, recid_train, recid_test = train_test_split(\n",
    "        X, recid, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    race_train = X_train[\"race_bin\"].values\n",
    "    race_test  = X_test[\"race_bin\"].values\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 4. COMBINAR RACE + RECID COMO TARGET PARA SMOTE (si aplica)\n",
    "    # --------------------------------------------------------\n",
    "    if sampler:\n",
    "\n",
    "        # target conjunto para fairness → 00,01,10,11\n",
    "        y_joint = np.array([f\"{r}{c}\" for r, c in zip(race_train, recid_train)])\n",
    "\n",
    "        # print(\"\\nTRAIN SET BEFORE SAMPLING:\")\n",
    "        # print(\"Black Non-rec:\", np.sum(y_joint == \"00\"))\n",
    "        # print(\"Black Recid:  \", np.sum(y_joint == \"01\"))\n",
    "        # print(\"White Non-rec:\", np.sum(y_joint == \"10\"))\n",
    "        # print(\"White Recid:  \", np.sum(y_joint == \"11\"))\n",
    "\n",
    "        # Resampling\n",
    "        X_train_res, y_joint_res = sampler.fit_resample(X_train, y_joint)\n",
    "\n",
    "        # print(\"\\nTRAIN SET AFTER SAMPLING:\")\n",
    "        # print(\"Black Non-rec:\", np.sum(y_joint_res == \"00\"))\n",
    "        # print(\"Black Recid:  \", np.sum(y_joint_res == \"01\"))\n",
    "        # print(\"White Non-rec:\", np.sum(y_joint_res == \"10\"))\n",
    "        # print(\"White Recid:  \", np.sum(y_joint_res == \"11\"))\n",
    "\n",
    "        # DESCOMPONER el label conjunto\n",
    "        race_train = np.array([int(y[0]) for y in y_joint_res])\n",
    "        recid_train = np.array([int(y[1]) for y in y_joint_res])\n",
    "\n",
    "        X_train_res[\"race_bin\"] = race_train\n",
    "        X_train = X_train_res.copy()\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 5. RESAMPLE TEST SET (OPCIONAL)\n",
    "    # --------------------------------------------------------\n",
    "    if resample_test and sampler:\n",
    "\n",
    "        y_joint_test = np.array([f\"{r}{c}\" for r, c in zip(race_test, recid_test)])\n",
    "\n",
    "        # print(\"\\nTEST SET BEFORE SAMPLING:\")\n",
    "        # print(\"Black Non-rec:\", np.sum(y_joint_test == \"00\"))\n",
    "        # print(\"Black Recid:  \", np.sum(y_joint_test == \"01\"))\n",
    "        # print(\"White Non-rec:\", np.sum(y_joint_test == \"10\"))\n",
    "        # print(\"White Recid:  \", np.sum(y_joint_test == \"11\"))\n",
    "\n",
    "        X_test_res, y_joint_test_res = sampler.fit_resample(X_test, y_joint_test)\n",
    "\n",
    "        # print(\"\\nTEST SET AFTER SAMPLING:\")\n",
    "        # print(\"Black Non-rec:\", np.sum(y_joint_test_res == \"00\"))\n",
    "        # print(\"Black Recid:  \", np.sum(y_joint_test_res == \"01\"))\n",
    "        # print(\"White Non-rec:\", np.sum(y_joint_test_res == \"10\"))\n",
    "        # print(\"White Recid:  \", np.sum(y_joint_test_res == \"11\"))\n",
    "\n",
    "        race_test  = np.array([int(y[0]) for y in y_joint_test_res])\n",
    "        recid_test = np.array([int(y[1]) for y in y_joint_test_res])\n",
    "\n",
    "        X_test = X_test_res.copy()\n",
    "        X_test[\"race_bin\"] = race_test\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 6. TRAIN MODEL\n",
    "    # --------------------------------------------------------\n",
    "    clf = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n",
    "    clf.fit(X_train, recid_train)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 7. PREDICT\n",
    "    # --------------------------------------------------------\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 8. FAIRNESS MASKS\n",
    "    # --------------------------------------------------------\n",
    "    black_mask = (race_test == 0)\n",
    "    white_mask = (race_test == 1)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 9. MÉTRICAS DE FAIRNESS\n",
    "    # --------------------------------------------------------\n",
    "    data = eval_fairness(y_pred, recid_test, black_mask, white_mask)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_resampler(df, sampler=None, resample_test=False):\n",
    "    \n",
    "    # --------------------------------------------------------\n",
    "    # 1. FILTRAR DATOS: Solo African-American y Caucasian\n",
    "    # --------------------------------------------------------\n",
    "    df_temp = df[(df[\"race\"] == \"African-American\") | (df[\"race\"] == \"Caucasian\")].copy()\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 2. PREPARACIÓN DE FEATURES\n",
    "    # --------------------------------------------------------\n",
    "    cols = [\"age\", \"sex\", \"priors_count\", \"score_text\"]\n",
    "    X = df_temp[cols].copy()\n",
    "\n",
    "    # score_text → 0 = Low, 1 = Medium/High\n",
    "    X[\"score_text\"] = (X[\"score_text\"] != \"Low\").astype(int)\n",
    "\n",
    "    # Codificar sex a 0/1\n",
    "    X[\"sex\"] = (X[\"sex\"] == \"Male\").astype(int)\n",
    "\n",
    "    # Codificar race a 0/1 para fairness\n",
    "    df_temp[\"race_bin\"] = (df_temp[\"race\"] == \"Caucasian\").astype(int)\n",
    "\n",
    "    # target recidivism (asegurar tipo entero)\n",
    "    recid = df_temp[\"two_year_recid\"].astype(int).values\n",
    "\n",
    "    # Añadimos la variable racial (0/1)\n",
    "    X[\"race_bin\"] = df_temp[\"race_bin\"].values\n",
    "\n",
    "    # One-hot encoding limpio\n",
    "    X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 3. SPLIT DATA\n",
    "    # --------------------------------------------------------\n",
    "    X_train, X_test, recid_train, recid_test = train_test_split(\n",
    "        X, recid, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    race_train = X_train[\"race_bin\"].values\n",
    "    race_test  = X_test[\"race_bin\"].values\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 4. COMBINAR RACE + RECID COMO TARGET PARA SMOTE (si aplica)\n",
    "    # --------------------------------------------------------\n",
    "    if sampler:\n",
    "\n",
    "        # target conjunto para fairness → 00,01,10,11\n",
    "        y_joint = np.array([f\"{r}{c}\" for r, c in zip(race_train, recid_train)])\n",
    "\n",
    "        # print(\"\\nTRAIN SET BEFORE SAMPLING:\")\n",
    "        # print(\"Black Non-rec:\", np.sum(y_joint == \"00\"))\n",
    "        # print(\"Black Recid:  \", np.sum(y_joint == \"01\"))\n",
    "        # print(\"White Non-rec:\", np.sum(y_joint == \"10\"))\n",
    "        # print(\"White Recid:  \", np.sum(y_joint == \"11\"))\n",
    "\n",
    "        # Resampling\n",
    "        X_train_res, y_joint_res = sampler.fit_resample(X_train, y_joint)\n",
    "\n",
    "        # print(\"\\nTRAIN SET AFTER SAMPLING:\")\n",
    "        # print(\"Black Non-rec:\", np.sum(y_joint_res == \"00\"))\n",
    "        # print(\"Black Recid:  \", np.sum(y_joint_res == \"01\"))\n",
    "        # print(\"White Non-rec:\", np.sum(y_joint_res == \"10\"))\n",
    "        # print(\"White Recid:  \", np.sum(y_joint_res == \"11\"))\n",
    "\n",
    "        # DESCOMPONER el label conjunto\n",
    "        race_train = np.array([int(y[0]) for y in y_joint_res])\n",
    "        recid_train = np.array([int(y[1]) for y in y_joint_res])\n",
    "\n",
    "        X_train_res[\"race_bin\"] = race_train\n",
    "        X_train = X_train_res.copy()\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 5. RESAMPLE TEST SET (OPCIONAL)\n",
    "    # --------------------------------------------------------\n",
    "    if resample_test and sampler:\n",
    "\n",
    "        y_joint_test = np.array([f\"{r}{c}\" for r, c in zip(race_test, recid_test)])\n",
    "\n",
    "        # print(\"\\nTEST SET BEFORE SAMPLING:\")\n",
    "        # print(\"Black Non-rec:\", np.sum(y_joint_test == \"00\"))\n",
    "        # print(\"Black Recid:  \", np.sum(y_joint_test == \"01\"))\n",
    "        # print(\"White Non-rec:\", np.sum(y_joint_test == \"10\"))\n",
    "        # print(\"White Recid:  \", np.sum(y_joint_test == \"11\"))\n",
    "\n",
    "        X_test_res, y_joint_test_res = sampler.fit_resample(X_test, y_joint_test)\n",
    "\n",
    "        # print(\"\\nTEST SET AFTER SAMPLING:\")\n",
    "        # print(\"Black Non-rec:\", np.sum(y_joint_test_res == \"00\"))\n",
    "        # print(\"Black Recid:  \", np.sum(y_joint_test_res == \"01\"))\n",
    "        # print(\"White Non-rec:\", np.sum(y_joint_test_res == \"10\"))\n",
    "        # print(\"White Recid:  \", np.sum(y_joint_test_res == \"11\"))\n",
    "\n",
    "        race_test  = np.array([int(y[0]) for y in y_joint_test_res])\n",
    "        recid_test = np.array([int(y[1]) for y in y_joint_test_res])\n",
    "\n",
    "        X_test = X_test_res.copy()\n",
    "        X_test[\"race_bin\"] = race_test\n",
    "    return X_train, X_test, recid_train, race_test, recid_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(X_train, X_test, recid_train, race_test, recid_test):\n",
    "    # --------------------------------------------------------\n",
    "    # 6. TRAIN MODEL\n",
    "    # --------------------------------------------------------\n",
    "    clf = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n",
    "    clf.fit(X_train, recid_train)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 7. PREDICT\n",
    "    # --------------------------------------------------------\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 8. FAIRNESS MASKS\n",
    "    # --------------------------------------------------------\n",
    "    black_mask = (race_test == 0)\n",
    "    white_mask = (race_test == 1)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 9. MÉTRICAS DE FAIRNESS\n",
    "    # --------------------------------------------------------\n",
    "    data = eval_fairness(y_pred, recid_test, black_mask, white_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_resampler(df, sampler=RandomUnderSampler(random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alvaronl/miniconda3/envs/jisbd/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [09:38:00] WARNING: /croot/xgboost-split_1724073744422/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/alvaronl/miniconda3/envs/jisbd/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [09:38:01] WARNING: /croot/xgboost-split_1724073744422/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/alvaronl/miniconda3/envs/jisbd/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [09:38:01] WARNING: /croot/xgboost-split_1724073744422/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/alvaronl/miniconda3/envs/jisbd/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [09:38:01] WARNING: /croot/xgboost-split_1724073744422/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/alvaronl/miniconda3/envs/jisbd/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [09:38:01] WARNING: /croot/xgboost-split_1724073744422/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/alvaronl/miniconda3/envs/jisbd/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [09:38:01] WARNING: /croot/xgboost-split_1724073744422/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/alvaronl/miniconda3/envs/jisbd/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [09:38:02] WARNING: /croot/xgboost-split_1724073744422/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "index= []\n",
    "\n",
    "index.append(\"Original Training - Original Test\")\n",
    "ev_0 = eval_resampler(df)\n",
    "# print(ev_0)\n",
    "data.append(ev_0)\n",
    "index.append(\"SMOTE Training - Original Test\")\n",
    "ev_1 = eval_resampler(df, sampler=SMOTE(random_state=42))\n",
    "# print(ev_1)\n",
    "data.append(ev_1)\n",
    "index.append(\"SMOTE Training - SMOTE Test\")\n",
    "data.append(eval_resampler(df, sampler=SMOTE(random_state=42), resample_test=True))\n",
    "index.append(\"Oversampling Training - Original Test\")\n",
    "data.append(eval_resampler(df, sampler=RandomOverSampler(random_state=42)))\n",
    "index.append(\"Oversampling Training - Oversampling Test\")\n",
    "data.append(eval_resampler(df, sampler=RandomOverSampler(random_state=42), resample_test=True))\n",
    "index.append(\"Undersampling Training - Original Test\")\n",
    "data.append(eval_resampler(df, sampler=RandomUnderSampler(random_state=42)))\n",
    "index.append(\"Undersampling Training - Undersampling Test\")\n",
    "data.append(eval_resampler(df, sampler=RandomUnderSampler(random_state=42), resample_test=True))\n",
    "\n",
    "\n",
    "# clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR_w</th>\n",
       "      <th>TPR_b</th>\n",
       "      <th>FPR_w</th>\n",
       "      <th>FPR_b</th>\n",
       "      <th>Eq. Oportunity</th>\n",
       "      <th>Pred. Equality</th>\n",
       "      <th>Eq. odds</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Original Training - Original Test</th>\n",
       "      <td>0.391753</td>\n",
       "      <td>0.648438</td>\n",
       "      <td>0.122112</td>\n",
       "      <td>0.332378</td>\n",
       "      <td>0.256685</td>\n",
       "      <td>0.210266</td>\n",
       "      <td>0.466951</td>\n",
       "      <td>0.669919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOTE Training - Original Test</th>\n",
       "      <td>0.536082</td>\n",
       "      <td>0.630208</td>\n",
       "      <td>0.267327</td>\n",
       "      <td>0.312321</td>\n",
       "      <td>0.094126</td>\n",
       "      <td>0.044994</td>\n",
       "      <td>0.139120</td>\n",
       "      <td>0.656911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOTE Training - SMOTE Test</th>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.630208</td>\n",
       "      <td>0.242188</td>\n",
       "      <td>0.309896</td>\n",
       "      <td>0.161458</td>\n",
       "      <td>0.067708</td>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.636719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oversampling Training - Original Test</th>\n",
       "      <td>0.541237</td>\n",
       "      <td>0.630208</td>\n",
       "      <td>0.270627</td>\n",
       "      <td>0.332378</td>\n",
       "      <td>0.088971</td>\n",
       "      <td>0.061751</td>\n",
       "      <td>0.150722</td>\n",
       "      <td>0.651220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oversampling Training - Oversampling Test</th>\n",
       "      <td>0.526042</td>\n",
       "      <td>0.630208</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.072917</td>\n",
       "      <td>0.177083</td>\n",
       "      <td>0.635417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Undersampling Training - Original Test</th>\n",
       "      <td>0.561856</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.254125</td>\n",
       "      <td>0.303725</td>\n",
       "      <td>0.083978</td>\n",
       "      <td>0.049600</td>\n",
       "      <td>0.133577</td>\n",
       "      <td>0.671545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Undersampling Training - Undersampling Test</th>\n",
       "      <td>0.561856</td>\n",
       "      <td>0.613402</td>\n",
       "      <td>0.268041</td>\n",
       "      <td>0.324742</td>\n",
       "      <td>0.051546</td>\n",
       "      <td>0.056701</td>\n",
       "      <td>0.108247</td>\n",
       "      <td>0.645619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                TPR_w     TPR_b     FPR_w  \\\n",
       "Original Training - Original Test            0.391753  0.648438  0.122112   \n",
       "SMOTE Training - Original Test               0.536082  0.630208  0.267327   \n",
       "SMOTE Training - SMOTE Test                  0.468750  0.630208  0.242188   \n",
       "Oversampling Training - Original Test        0.541237  0.630208  0.270627   \n",
       "Oversampling Training - Oversampling Test    0.526042  0.630208  0.270833   \n",
       "Undersampling Training - Original Test       0.561856  0.645833  0.254125   \n",
       "Undersampling Training - Undersampling Test  0.561856  0.613402  0.268041   \n",
       "\n",
       "                                                FPR_b  Eq. Oportunity  \\\n",
       "Original Training - Original Test            0.332378        0.256685   \n",
       "SMOTE Training - Original Test               0.312321        0.094126   \n",
       "SMOTE Training - SMOTE Test                  0.309896        0.161458   \n",
       "Oversampling Training - Original Test        0.332378        0.088971   \n",
       "Oversampling Training - Oversampling Test    0.343750        0.104167   \n",
       "Undersampling Training - Original Test       0.303725        0.083978   \n",
       "Undersampling Training - Undersampling Test  0.324742        0.051546   \n",
       "\n",
       "                                             Pred. Equality  Eq. odds  \\\n",
       "Original Training - Original Test                  0.210266  0.466951   \n",
       "SMOTE Training - Original Test                     0.044994  0.139120   \n",
       "SMOTE Training - SMOTE Test                        0.067708  0.229167   \n",
       "Oversampling Training - Original Test              0.061751  0.150722   \n",
       "Oversampling Training - Oversampling Test          0.072917  0.177083   \n",
       "Undersampling Training - Original Test             0.049600  0.133577   \n",
       "Undersampling Training - Undersampling Test        0.056701  0.108247   \n",
       "\n",
       "                                             Accuracy  \n",
       "Original Training - Original Test            0.669919  \n",
       "SMOTE Training - Original Test               0.656911  \n",
       "SMOTE Training - SMOTE Test                  0.636719  \n",
       "Oversampling Training - Original Test        0.651220  \n",
       "Oversampling Training - Oversampling Test    0.635417  \n",
       "Undersampling Training - Original Test       0.671545  \n",
       "Undersampling Training - Undersampling Test  0.645619  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data, index=index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a different classifier for each race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15014/1343833303.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['score_text'] = [0 if y_i == 'Low' else 1 for y_i in X['score_text']]\n",
      "/home/alvaronl/miniconda3/envs/jisbd/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [09:38:14] WARNING: /croot/xgboost-split_1724073744422/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/alvaronl/miniconda3/envs/jisbd/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [09:38:15] WARNING: /croot/xgboost-split_1724073744422/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "df_temp = df[(df['race'] == 'African-American') | (df['race'] == 'Caucasian')]\n",
    "cols = ['age', 'sex', 'race', 'priors_count', 'score_text']\n",
    "X, recid = df_temp[cols], df_temp['two_year_recid']\n",
    "X['score_text'] = [0 if y_i == 'Low' else 1 for y_i in X['score_text']]\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "X_train, X_test, recid_train, recid_test = train_test_split(X, recid.values, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a classifier for each race\n",
    "X_train_black, recid_train_black = X_train[X_train['race_Caucasian'] == 0], recid_train[X_train['race_Caucasian'] == 0]\n",
    "X_train_white, recid_train_white = X_train[X_train['race_Caucasian'] == 1], recid_train[X_train['race_Caucasian'] == 1]\n",
    "# Get score text in order to train\n",
    "X_train_black, y_train_black = X_train_black.drop(columns='score_text'), X_train_black['score_text']\n",
    "X_train_white, y_train_white = X_train_white.drop(columns='score_text'), X_train_white['score_text']\n",
    "\n",
    "clf_black = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "clf_white = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Fit the models\n",
    "clf_black.fit(X_train_black, y_train_black)\n",
    "clf_white.fit(X_train_white, y_train_white)\n",
    "\n",
    "# Make predictions\n",
    "X_test_black, recid_test_black = X_test[X_test['race_Caucasian'] == 0], recid_test[X_test['race_Caucasian'] == 0]\n",
    "X_test_white, recid_test_white = X_test[X_test['race_Caucasian'] == 1], recid_test[X_test['race_Caucasian'] == 1]\n",
    "# Get score text in order to train\n",
    "X_test_black, y_test_black = X_test_black.drop(columns='score_text'), X_test_black['score_text']\n",
    "X_test_white, y_test_white = X_test_white.drop(columns='score_text'), X_test_white['score_text']\n",
    "\n",
    "y_pred_black = clf_black.predict(X_test_black)\n",
    "y_pred_white = clf_white.predict(X_test_white)\n",
    "y_pred = np.concatenate((y_pred_black, y_pred_white))\n",
    "recid_test = np.concatenate((recid_test_black, recid_test_white))\n",
    "black_mask = np.array([True]*len(y_pred_black) + [False]*len(y_pred_white))\n",
    "white_mask = np.array([False]*len(y_pred_black) + [True]*len(y_pred_white))\n",
    "\n",
    "index.append(\"Split by race\")\n",
    "data.append(eval_fairness(y_pred, recid_test, black_mask, white_mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing race attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15014/3617425854.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['score_text'] = [0 if y_i == 'Low' else 1 for y_i in X['score_text']]\n",
      "/home/alvaronl/miniconda3/envs/jisbd/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [09:38:18] WARNING: /croot/xgboost-split_1724073744422/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Train without the race variable\n",
    "df_temp = df[(df['race'] == 'African-American') | (df['race'] == 'Caucasian')]\n",
    "cols = ['age', 'sex', 'race', 'priors_count', 'score_text']\n",
    "X, recid = df_temp[cols], df_temp['two_year_recid']\n",
    "X['score_text'] = [0 if y_i == 'Low' else 1 for y_i in X['score_text']]\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "X_train, X_test, recid_train, recid_test = train_test_split(X, recid.values, test_size=0.2, random_state=42)\n",
    "\n",
    "# drop the race\n",
    "X_train, y_train = X_train.drop(columns=['race_Caucasian', 'score_text']), X_train['score_text']\n",
    "# Train the model without race\n",
    "clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = clf.predict(X_test.drop(columns=['race_Caucasian', 'score_text']))\n",
    "black_mask = X_test['race_Caucasian'] == 0\n",
    "white_mask = X_test['race_Caucasian'] == 1 \n",
    "\n",
    "index.append(\"Remove race attribute\")\n",
    "data.append(eval_fairness(y_pred, recid_test, black_mask, white_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(data, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR_w</th>\n",
       "      <th>TPR_b</th>\n",
       "      <th>FPR_w</th>\n",
       "      <th>FPR_b</th>\n",
       "      <th>Eq. Oportunity</th>\n",
       "      <th>Pred. Equality</th>\n",
       "      <th>Eq. odds</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Original Training - Original Test</th>\n",
       "      <td>0.391753</td>\n",
       "      <td>0.648438</td>\n",
       "      <td>0.122112</td>\n",
       "      <td>0.332378</td>\n",
       "      <td>0.256685</td>\n",
       "      <td>0.210266</td>\n",
       "      <td>0.466951</td>\n",
       "      <td>0.669919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOTE Training - Original Test</th>\n",
       "      <td>0.536082</td>\n",
       "      <td>0.630208</td>\n",
       "      <td>0.267327</td>\n",
       "      <td>0.312321</td>\n",
       "      <td>0.094126</td>\n",
       "      <td>0.044994</td>\n",
       "      <td>0.139120</td>\n",
       "      <td>0.656911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOTE Training - SMOTE Test</th>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.630208</td>\n",
       "      <td>0.242188</td>\n",
       "      <td>0.309896</td>\n",
       "      <td>0.161458</td>\n",
       "      <td>0.067708</td>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.636719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oversampling Training - Original Test</th>\n",
       "      <td>0.541237</td>\n",
       "      <td>0.630208</td>\n",
       "      <td>0.270627</td>\n",
       "      <td>0.332378</td>\n",
       "      <td>0.088971</td>\n",
       "      <td>0.061751</td>\n",
       "      <td>0.150722</td>\n",
       "      <td>0.651220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oversampling Training - Oversampling Test</th>\n",
       "      <td>0.526042</td>\n",
       "      <td>0.630208</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.072917</td>\n",
       "      <td>0.177083</td>\n",
       "      <td>0.635417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Undersampling Training - Original Test</th>\n",
       "      <td>0.561856</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.254125</td>\n",
       "      <td>0.303725</td>\n",
       "      <td>0.083978</td>\n",
       "      <td>0.049600</td>\n",
       "      <td>0.133577</td>\n",
       "      <td>0.671545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Undersampling Training - Undersampling Test</th>\n",
       "      <td>0.561856</td>\n",
       "      <td>0.613402</td>\n",
       "      <td>0.268041</td>\n",
       "      <td>0.324742</td>\n",
       "      <td>0.051546</td>\n",
       "      <td>0.056701</td>\n",
       "      <td>0.108247</td>\n",
       "      <td>0.645619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Split by race</th>\n",
       "      <td>0.355670</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.188119</td>\n",
       "      <td>0.389685</td>\n",
       "      <td>0.347455</td>\n",
       "      <td>0.201566</td>\n",
       "      <td>0.549021</td>\n",
       "      <td>0.648780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Remove race attribute</th>\n",
       "      <td>0.407216</td>\n",
       "      <td>0.674479</td>\n",
       "      <td>0.181518</td>\n",
       "      <td>0.355301</td>\n",
       "      <td>0.267263</td>\n",
       "      <td>0.173783</td>\n",
       "      <td>0.441045</td>\n",
       "      <td>0.659350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                TPR_w     TPR_b     FPR_w  \\\n",
       "Original Training - Original Test            0.391753  0.648438  0.122112   \n",
       "SMOTE Training - Original Test               0.536082  0.630208  0.267327   \n",
       "SMOTE Training - SMOTE Test                  0.468750  0.630208  0.242188   \n",
       "Oversampling Training - Original Test        0.541237  0.630208  0.270627   \n",
       "Oversampling Training - Oversampling Test    0.526042  0.630208  0.270833   \n",
       "Undersampling Training - Original Test       0.561856  0.645833  0.254125   \n",
       "Undersampling Training - Undersampling Test  0.561856  0.613402  0.268041   \n",
       "Split by race                                0.355670  0.703125  0.188119   \n",
       "Remove race attribute                        0.407216  0.674479  0.181518   \n",
       "\n",
       "                                                FPR_b  Eq. Oportunity  \\\n",
       "Original Training - Original Test            0.332378        0.256685   \n",
       "SMOTE Training - Original Test               0.312321        0.094126   \n",
       "SMOTE Training - SMOTE Test                  0.309896        0.161458   \n",
       "Oversampling Training - Original Test        0.332378        0.088971   \n",
       "Oversampling Training - Oversampling Test    0.343750        0.104167   \n",
       "Undersampling Training - Original Test       0.303725        0.083978   \n",
       "Undersampling Training - Undersampling Test  0.324742        0.051546   \n",
       "Split by race                                0.389685        0.347455   \n",
       "Remove race attribute                        0.355301        0.267263   \n",
       "\n",
       "                                             Pred. Equality  Eq. odds  \\\n",
       "Original Training - Original Test                  0.210266  0.466951   \n",
       "SMOTE Training - Original Test                     0.044994  0.139120   \n",
       "SMOTE Training - SMOTE Test                        0.067708  0.229167   \n",
       "Oversampling Training - Original Test              0.061751  0.150722   \n",
       "Oversampling Training - Oversampling Test          0.072917  0.177083   \n",
       "Undersampling Training - Original Test             0.049600  0.133577   \n",
       "Undersampling Training - Undersampling Test        0.056701  0.108247   \n",
       "Split by race                                      0.201566  0.549021   \n",
       "Remove race attribute                              0.173783  0.441045   \n",
       "\n",
       "                                             Accuracy  \n",
       "Original Training - Original Test            0.669919  \n",
       "SMOTE Training - Original Test               0.656911  \n",
       "SMOTE Training - SMOTE Test                  0.636719  \n",
       "Oversampling Training - Original Test        0.651220  \n",
       "Oversampling Training - Oversampling Test    0.635417  \n",
       "Undersampling Training - Original Test       0.671545  \n",
       "Undersampling Training - Undersampling Test  0.645619  \n",
       "Split by race                                0.648780  \n",
       "Remove race attribute                        0.659350  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3db12_row0_col0, #T_3db12_row7_col3 {\n",
       "  background-color: #e3d9d3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3db12_row0_col1, #T_3db12_row7_col7 {\n",
       "  background-color: #d1493f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3db12_row0_col2 {\n",
       "  background-color: #5e7de7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3db12_row0_col3, #T_3db12_row3_col3 {\n",
       "  background-color: #cbd8ee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3db12_row0_col4 {\n",
       "  background-color: #a6c4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3db12_row0_col5 {\n",
       "  background-color: #8db0fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3db12_row0_col6, #T_3db12_row2_col0 {\n",
       "  background-color: #f6bfa6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3db12_row0_col7, #T_3db12_row5_col7 {\n",
       "  background-color: #c53334;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3db12_row1_col0 {\n",
       "  background-color: #f49a7b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3db12_row1_col1, #T_3db12_row2_col1, #T_3db12_row3_col1, #T_3db12_row4_col1 {\n",
       "  background-color: #d95847;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3db12_row1_col2, #T_3db12_row6_col2, #T_3db12_row8_col4 {\n",
       "  background-color: #abc8fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3db12_row1_col3, #T_3db12_row2_col3 {\n",
       "  background-color: #c1d4f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3db12_row1_col4 {\n",
       "  background-color: #516ddb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3db12_row1_col5 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3db12_row1_col6 {\n",
       "  background-color: #6788ee;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3db12_row1_col7, #T_3db12_row8_col7 {\n",
       "  background-color: #cc403a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3db12_row2_col2 {\n",
       "  background-color: #9ebeff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3db12_row2_col4 {\n",
       "  background-color: #7396f5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3db12_row2_col5 {\n",
       "  background-color: #445acc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3db12_row2_col6 {\n",
       "  background-color: #97b8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3db12_row2_col7 {\n",
       "  background-color: #d65244;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3db12_row3_col0 {\n",
       "  background-color: #f39778;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3db12_row3_col2, #T_3db12_row4_col2 {\n",
       "  background-color: #adc9fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3db12_row3_col4 {\n",
       "  background-color: #4f69d9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3db12_row3_col5 {\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3db12_row3_col6 {\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3db12_row3_col7 {\n",
       "  background-color: #d0473d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3db12_row4_col0 {\n",
       "  background-color: #f5a081;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3db12_row4_col3 {\n",
       "  background-color: #d1dae9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3db12_row4_col4 {\n",
       "  background-color: #5673e0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3db12_row4_col5 {\n",
       "  background-color: #465ecf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3db12_row4_col6 {\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3db12_row4_col7 {\n",
       "  background-color: #d75445;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3db12_row5_col0, #T_3db12_row6_col0 {\n",
       "  background-color: #f08a6c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3db12_row5_col1, #T_3db12_row6_col7 {\n",
       "  background-color: #d24b40;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3db12_row5_col2 {\n",
       "  background-color: #a5c3fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3db12_row5_col3 {\n",
       "  background-color: #bed2f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3db12_row5_col4 {\n",
       "  background-color: #4c66d6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3db12_row5_col5 {\n",
       "  background-color: #3c4ec2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3db12_row5_col6 {\n",
       "  background-color: #6485ec;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3db12_row6_col1 {\n",
       "  background-color: #e0654f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3db12_row6_col3 {\n",
       "  background-color: #c7d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3db12_row6_col4 {\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3db12_row6_col5 {\n",
       "  background-color: #3f53c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3db12_row6_col6 {\n",
       "  background-color: #5875e1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3db12_row7_col0, #T_3db12_row8_col3 {\n",
       "  background-color: #d5dbe5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3db12_row7_col1 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3db12_row7_col2 {\n",
       "  background-color: #81a4fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3db12_row7_col4 {\n",
       "  background-color: #d2dbe8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3db12_row7_col5 {\n",
       "  background-color: #88abfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3db12_row7_col6 {\n",
       "  background-color: #f29274;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3db12_row8_col0 {\n",
       "  background-color: #e9d5cb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3db12_row8_col1 {\n",
       "  background-color: #c43032;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3db12_row8_col2 {\n",
       "  background-color: #7ea1fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3db12_row8_col5 {\n",
       "  background-color: #7a9df8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3db12_row8_col6 {\n",
       "  background-color: #f2cab5;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3db12\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3db12_level0_col0\" class=\"col_heading level0 col0\" >TPR_w</th>\n",
       "      <th id=\"T_3db12_level0_col1\" class=\"col_heading level0 col1\" >TPR_b</th>\n",
       "      <th id=\"T_3db12_level0_col2\" class=\"col_heading level0 col2\" >FPR_w</th>\n",
       "      <th id=\"T_3db12_level0_col3\" class=\"col_heading level0 col3\" >FPR_b</th>\n",
       "      <th id=\"T_3db12_level0_col4\" class=\"col_heading level0 col4\" >Eq. Oportunity</th>\n",
       "      <th id=\"T_3db12_level0_col5\" class=\"col_heading level0 col5\" >Pred. Equality</th>\n",
       "      <th id=\"T_3db12_level0_col6\" class=\"col_heading level0 col6\" >Eq. odds</th>\n",
       "      <th id=\"T_3db12_level0_col7\" class=\"col_heading level0 col7\" >Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3db12_level0_row0\" class=\"row_heading level0 row0\" >Original Training - Original Test</th>\n",
       "      <td id=\"T_3db12_row0_col0\" class=\"data row0 col0\" >0.39</td>\n",
       "      <td id=\"T_3db12_row0_col1\" class=\"data row0 col1\" >0.65</td>\n",
       "      <td id=\"T_3db12_row0_col2\" class=\"data row0 col2\" >0.12</td>\n",
       "      <td id=\"T_3db12_row0_col3\" class=\"data row0 col3\" >0.33</td>\n",
       "      <td id=\"T_3db12_row0_col4\" class=\"data row0 col4\" >0.26</td>\n",
       "      <td id=\"T_3db12_row0_col5\" class=\"data row0 col5\" >0.21</td>\n",
       "      <td id=\"T_3db12_row0_col6\" class=\"data row0 col6\" >0.47</td>\n",
       "      <td id=\"T_3db12_row0_col7\" class=\"data row0 col7\" >0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3db12_level0_row1\" class=\"row_heading level0 row1\" >SMOTE Training - Original Test</th>\n",
       "      <td id=\"T_3db12_row1_col0\" class=\"data row1 col0\" >0.54</td>\n",
       "      <td id=\"T_3db12_row1_col1\" class=\"data row1 col1\" >0.63</td>\n",
       "      <td id=\"T_3db12_row1_col2\" class=\"data row1 col2\" >0.27</td>\n",
       "      <td id=\"T_3db12_row1_col3\" class=\"data row1 col3\" >0.31</td>\n",
       "      <td id=\"T_3db12_row1_col4\" class=\"data row1 col4\" >0.09</td>\n",
       "      <td id=\"T_3db12_row1_col5\" class=\"data row1 col5\" >0.04</td>\n",
       "      <td id=\"T_3db12_row1_col6\" class=\"data row1 col6\" >0.14</td>\n",
       "      <td id=\"T_3db12_row1_col7\" class=\"data row1 col7\" >0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3db12_level0_row2\" class=\"row_heading level0 row2\" >SMOTE Training - SMOTE Test</th>\n",
       "      <td id=\"T_3db12_row2_col0\" class=\"data row2 col0\" >0.47</td>\n",
       "      <td id=\"T_3db12_row2_col1\" class=\"data row2 col1\" >0.63</td>\n",
       "      <td id=\"T_3db12_row2_col2\" class=\"data row2 col2\" >0.24</td>\n",
       "      <td id=\"T_3db12_row2_col3\" class=\"data row2 col3\" >0.31</td>\n",
       "      <td id=\"T_3db12_row2_col4\" class=\"data row2 col4\" >0.16</td>\n",
       "      <td id=\"T_3db12_row2_col5\" class=\"data row2 col5\" >0.07</td>\n",
       "      <td id=\"T_3db12_row2_col6\" class=\"data row2 col6\" >0.23</td>\n",
       "      <td id=\"T_3db12_row2_col7\" class=\"data row2 col7\" >0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3db12_level0_row3\" class=\"row_heading level0 row3\" >Oversampling Training - Original Test</th>\n",
       "      <td id=\"T_3db12_row3_col0\" class=\"data row3 col0\" >0.54</td>\n",
       "      <td id=\"T_3db12_row3_col1\" class=\"data row3 col1\" >0.63</td>\n",
       "      <td id=\"T_3db12_row3_col2\" class=\"data row3 col2\" >0.27</td>\n",
       "      <td id=\"T_3db12_row3_col3\" class=\"data row3 col3\" >0.33</td>\n",
       "      <td id=\"T_3db12_row3_col4\" class=\"data row3 col4\" >0.09</td>\n",
       "      <td id=\"T_3db12_row3_col5\" class=\"data row3 col5\" >0.06</td>\n",
       "      <td id=\"T_3db12_row3_col6\" class=\"data row3 col6\" >0.15</td>\n",
       "      <td id=\"T_3db12_row3_col7\" class=\"data row3 col7\" >0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3db12_level0_row4\" class=\"row_heading level0 row4\" >Oversampling Training - Oversampling Test</th>\n",
       "      <td id=\"T_3db12_row4_col0\" class=\"data row4 col0\" >0.53</td>\n",
       "      <td id=\"T_3db12_row4_col1\" class=\"data row4 col1\" >0.63</td>\n",
       "      <td id=\"T_3db12_row4_col2\" class=\"data row4 col2\" >0.27</td>\n",
       "      <td id=\"T_3db12_row4_col3\" class=\"data row4 col3\" >0.34</td>\n",
       "      <td id=\"T_3db12_row4_col4\" class=\"data row4 col4\" >0.10</td>\n",
       "      <td id=\"T_3db12_row4_col5\" class=\"data row4 col5\" >0.07</td>\n",
       "      <td id=\"T_3db12_row4_col6\" class=\"data row4 col6\" >0.18</td>\n",
       "      <td id=\"T_3db12_row4_col7\" class=\"data row4 col7\" >0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3db12_level0_row5\" class=\"row_heading level0 row5\" >Undersampling Training - Original Test</th>\n",
       "      <td id=\"T_3db12_row5_col0\" class=\"data row5 col0\" >0.56</td>\n",
       "      <td id=\"T_3db12_row5_col1\" class=\"data row5 col1\" >0.65</td>\n",
       "      <td id=\"T_3db12_row5_col2\" class=\"data row5 col2\" >0.25</td>\n",
       "      <td id=\"T_3db12_row5_col3\" class=\"data row5 col3\" >0.30</td>\n",
       "      <td id=\"T_3db12_row5_col4\" class=\"data row5 col4\" >0.08</td>\n",
       "      <td id=\"T_3db12_row5_col5\" class=\"data row5 col5\" >0.05</td>\n",
       "      <td id=\"T_3db12_row5_col6\" class=\"data row5 col6\" >0.13</td>\n",
       "      <td id=\"T_3db12_row5_col7\" class=\"data row5 col7\" >0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3db12_level0_row6\" class=\"row_heading level0 row6\" >Undersampling Training - Undersampling Test</th>\n",
       "      <td id=\"T_3db12_row6_col0\" class=\"data row6 col0\" >0.56</td>\n",
       "      <td id=\"T_3db12_row6_col1\" class=\"data row6 col1\" >0.61</td>\n",
       "      <td id=\"T_3db12_row6_col2\" class=\"data row6 col2\" >0.27</td>\n",
       "      <td id=\"T_3db12_row6_col3\" class=\"data row6 col3\" >0.32</td>\n",
       "      <td id=\"T_3db12_row6_col4\" class=\"data row6 col4\" >0.05</td>\n",
       "      <td id=\"T_3db12_row6_col5\" class=\"data row6 col5\" >0.06</td>\n",
       "      <td id=\"T_3db12_row6_col6\" class=\"data row6 col6\" >0.11</td>\n",
       "      <td id=\"T_3db12_row6_col7\" class=\"data row6 col7\" >0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3db12_level0_row7\" class=\"row_heading level0 row7\" >Split by race</th>\n",
       "      <td id=\"T_3db12_row7_col0\" class=\"data row7 col0\" >0.36</td>\n",
       "      <td id=\"T_3db12_row7_col1\" class=\"data row7 col1\" >0.70</td>\n",
       "      <td id=\"T_3db12_row7_col2\" class=\"data row7 col2\" >0.19</td>\n",
       "      <td id=\"T_3db12_row7_col3\" class=\"data row7 col3\" >0.39</td>\n",
       "      <td id=\"T_3db12_row7_col4\" class=\"data row7 col4\" >0.35</td>\n",
       "      <td id=\"T_3db12_row7_col5\" class=\"data row7 col5\" >0.20</td>\n",
       "      <td id=\"T_3db12_row7_col6\" class=\"data row7 col6\" >0.55</td>\n",
       "      <td id=\"T_3db12_row7_col7\" class=\"data row7 col7\" >0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3db12_level0_row8\" class=\"row_heading level0 row8\" >Remove race attribute</th>\n",
       "      <td id=\"T_3db12_row8_col0\" class=\"data row8 col0\" >0.41</td>\n",
       "      <td id=\"T_3db12_row8_col1\" class=\"data row8 col1\" >0.67</td>\n",
       "      <td id=\"T_3db12_row8_col2\" class=\"data row8 col2\" >0.18</td>\n",
       "      <td id=\"T_3db12_row8_col3\" class=\"data row8 col3\" >0.36</td>\n",
       "      <td id=\"T_3db12_row8_col4\" class=\"data row8 col4\" >0.27</td>\n",
       "      <td id=\"T_3db12_row8_col5\" class=\"data row8 col5\" >0.17</td>\n",
       "      <td id=\"T_3db12_row8_col6\" class=\"data row8 col6\" >0.44</td>\n",
       "      <td id=\"T_3db12_row8_col7\" class=\"data row8 col7\" >0.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x76230c9afac0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.style \\\n",
    "    .format(\"{:.2f}\") \\\n",
    "    .background_gradient(\n",
    "        cmap=\"coolwarm\",  # azul = bajo, rojo = alto\n",
    "        axis=None         # usar toda la tabla para calcular rangos\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jisbd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
